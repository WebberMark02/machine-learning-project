{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WebberMark02/machine-learning-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji71gvVwqCty"
      },
      "source": [
        "Importo le librerie necessarie e scelgo di utilizzare \"tensorflow\" come\n",
        "backend per \"Keras\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zn_bDCHqCtz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miIes5RmqCt0"
      },
      "source": [
        "Imposto le variabili globali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyEC7p3vqCt0"
      },
      "outputs": [],
      "source": [
        "# TODO: Incrementa il numero di campioni di training e il numero di campioni di validation.\n",
        "# Per capire a quanto impostarli, calcola il numero massimo di possibili combinazioni di due immagini nel\n",
        "# training set di Cifar10 e il numero massimo di possibili combinazioni di due immagini nel validation set di 10000\n",
        "# immagini ottenuto dal training set di Cifar10.\n",
        "\n",
        "seed = 42\n",
        "training_set_size = 200000\n",
        "testing_set_size = 10000\n",
        "validation_set_size = 20000\n",
        "image_shape = (32, 32, 3)\n",
        "batch_size = 256\n",
        "epochs = 250\n",
        "learning_rate = 0.001\n",
        "l2 = 0.0\n",
        "early_stopping_patience = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30qeV0dSqCt1"
      },
      "source": [
        "Definisco il generatore di immagini sulle quali il modello verrà addestrato e testato.\n",
        "Il generatore restituisce \"batchsize\" immagini; ogni immagine è la media di due immagini\n",
        "scelte casualmente rispettivamente da X1 e X2.\n",
        "Il generatore restituisce, inoltre, una coppia di matrici, che possiamo denotare con y.\n",
        "y[0][i] e y[1][i] sono, rispettivamente, la classe della prima componente e la classe della seconda componente\n",
        "della immagine i-esima.\n",
        "Ogni classe è rappresentata con un vettore di lunghezza 5 dove ogni elemento è nullo tranne quello\n",
        "il cui indice corrisponde alla classe stessa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAj13zFWqCt1"
      },
      "outputs": [],
      "source": [
        "def datagenerator(x1,x2,y1,y2,batchsize):\n",
        "  # Numero di immagini in X1\n",
        "  size1 = x1.shape[0]\n",
        "  # Numero di immagini in X2\n",
        "  size2 = x2.shape[0]\n",
        "\n",
        "  # Trasforma, per esempio, [0, 1, 2] in [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "  y1_cat = keras.utils.to_categorical(y1, num_classes=5)\n",
        "  y2_cat = keras.utils.to_categorical(y2-5, num_classes=5)\n",
        "\n",
        "  while True:\n",
        "    num1 = np.random.randint(0, size1, batchsize)\n",
        "    num2 = np.random.randint(0, size2, batchsize)\n",
        "    x_data = (x1[num1] + x2[num2]) / 2.0\n",
        "    y_data = [y1_cat[num1],y2_cat[num2]]\n",
        "\n",
        "    yield x_data, y_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI-3l7LkqCt2"
      },
      "source": [
        "Definisco una funzione per il controllo del bilanciamento delle classi.\n",
        "Mi servirà per verificare che la divisione stratificata del training set\n",
        "di Cifar10 in training set e validation set abbia avuto successo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtxwvO74qCt2"
      },
      "outputs": [],
      "source": [
        "def stampa_percentuale( y, title=\"\" ):\n",
        "  if title:print(title)\n",
        "  # Calcoliamo le occorrenze di ciascuna classe nel dataset\n",
        "  unique, counts = np.unique(y, return_counts=True)\n",
        "  percentuali = (counts / len(y)) * 100 # calcolo la % di occorrenze per ciascuna classe\n",
        "  # Stampiamo le occorrenze e le percentuali\n",
        "  for classe, conteggio, percentuale in zip(unique, counts, percentuali):\n",
        "      print(f\"Classe {classe}: Occorrenze = {conteggio}, Percentuale {percentuale} %\" )\n",
        "  print(f\"Totale occorrenze : {sum(counts)}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco un modello casuale.\n",
        "Mi servirà per valutare che la rete abbia prestazioni migliori di quelle casuali."
      ],
      "metadata": {
        "id": "SNNprRV8v033"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_model(x):\n",
        "  #the random model ingnore the input x and return a pair of random classes\n",
        "  return(np.random.randint(0,5,(10000,2)))"
      ],
      "metadata": {
        "id": "qbYGmmyqv0Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgeP1UEnqCt2"
      },
      "source": [
        "Ora ha inizio la fase di caricamento e pre-processing dei dataset che verranno utilizzati\n",
        "per addestrare e esaminare le prestazioni della rete.\n",
        "\n",
        "Prima di tutto, carico il training set e il testing set di Cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JS5gpBXqCt2"
      },
      "outputs": [],
      "source": [
        "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = keras.datasets.cifar10.load_data()\n",
        "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
        "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
        "assert cifar10_y_train.shape == (50000, 1)\n",
        "assert cifar10_y_test.shape == (10000, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O68Ad-pJqCt3"
      },
      "outputs": [],
      "source": [
        "# Tutte le possibili classi di Cifar10\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNWVxIILqCt3"
      },
      "source": [
        "Normalizzo i valori dei pixel delle immagini di Cifar10 nell'intervallo [0,1] così da poterle dare in input\n",
        "alla rete neurale che costruirò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjDoQSV_qCt3"
      },
      "outputs": [],
      "source": [
        "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
        "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge_J0AJ1qCt3"
      },
      "source": [
        "Controllo il bilanciamento delle classi nel training set prima della divisione stratificata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDnBTrgMqCt3"
      },
      "outputs": [],
      "source": [
        "stampa_percentuale(cifar10_y_train, 'Training set completo')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSsO-Z5ZqCt3"
      },
      "source": [
        "Divido il training set di Cifar10 in due insiemi: il training set e il validation set.\n",
        "Quest'ultimo verrà usato per l'ottimizzazione degli iper-parametri della rete.\n",
        "Il validation set conterrà il 20% delle immagini del training set di Cifar10.\n",
        "Uso la stratificazione per mantenere le classi nelle stesse proporzioni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apJDIWaCqCt3"
      },
      "outputs": [],
      "source": [
        "cifar10_x_train, cifar10_x_val, cifar10_y_train, cifar10_y_val = sklearn.model_selection.train_test_split(cifar10_x_train, cifar10_y_train, test_size=0.2, stratify=cifar10_y_train, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi5EG-Q8qCt4"
      },
      "source": [
        "Controllo il bilanciamento delle classi nel training set e nel validation set ottenuti dalla divisione stratificata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeh22ElfqCt4"
      },
      "outputs": [],
      "source": [
        "stampa_percentuale(cifar10_y_train, 'Training set risultante')\n",
        "stampa_percentuale(cifar10_y_val, 'Validation set risultante')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E4iFjAiqCt4"
      },
      "source": [
        "Divido le immagini in due gruppi: un gruppo per le etichette [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\"]\n",
        "e un secondo gruppo per le etichette [\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18GrCDXSqCt4"
      },
      "outputs": [],
      "source": [
        "cond_1 = cifar10_y_train[:,0] < 5\n",
        "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
        "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
        "\n",
        "cond_2 = cifar10_y_train[:,0] >= 5\n",
        "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
        "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
        "\n",
        "cond_1_test = cifar10_y_test[:,0] < 5\n",
        "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
        "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
        "\n",
        "cond_2_test = cifar10_y_test[:,0] >= 5\n",
        "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
        "cifar10_y_test_2 = cifar10_y_test[cond_2_test]\n",
        "\n",
        "cond_1_val = cifar10_y_val[:,0] < 5\n",
        "cifar10_x_val_1 = cifar10_x_val[cond_1_val]\n",
        "cifar10_y_val_1 = cifar10_y_val[cond_1_val]\n",
        "\n",
        "cond_2_val = cifar10_y_val[:,0] >= 5\n",
        "cifar10_x_val_2 = cifar10_x_val[cond_2_val]\n",
        "cifar10_y_val_2 = cifar10_y_val[cond_2_val]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF_w3Lh3qCt4"
      },
      "source": [
        "Creo tre istanze del generatore per generare il training set, il validation set e il testing set finali."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23CmLchHqCt4"
      },
      "outputs": [],
      "source": [
        "traingen = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, training_set_size)\n",
        "valgen = datagenerator(cifar10_x_val_1, cifar10_x_val_2, cifar10_y_val_1, cifar10_y_val_2, validation_set_size)\n",
        "testgen = datagenerator(cifar10_x_test_1, cifar10_x_test_2, cifar10_y_test_1, cifar10_y_test_2, testing_set_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_96ykmoPqCt5"
      },
      "source": [
        "Creo il training set e il validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaRdDarAqCt5"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = next(traingen)\n",
        "x_val, y_val = next(valgen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Uk8azZqCt5"
      },
      "source": [
        "Verifico che le dimensioni dei due dataset siano corrette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEtPWDEnqCt5"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "print(len(y_train))\n",
        "print(len(y_val))\n",
        "\n",
        "print(y_train[0].shape)\n",
        "print(y_train[1].shape)\n",
        "print(y_val[0].shape)\n",
        "print(y_val[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TArvk3SDqCt5"
      },
      "source": [
        "Controllo che i valori dei pixel delle immagini appartengano all'intervallo [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Inp-IFlqCt5"
      },
      "outputs": [],
      "source": [
        "print(np.min(x_train[0]), np.max(x_train[0]))\n",
        "print(np.min(x_val[0]), np.max(x_val[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fase di preparazione dei dataset è completa.\n",
        "Ora viene definita la rete neurale."
      ],
      "metadata": {
        "id": "h0Hfc9iTsewO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_neural_network():\n",
        "  inputs = keras.Input(shape = image_shape, name = 'InputImage')\n",
        "  conv = keras.layers.Conv2D(\n",
        "                            filters=3,                    # The number of filters\n",
        "                            kernel_size=(5, 5),           # Height and width of the 2D Convolution window.\n",
        "                            strides=(1, 1),               # (Height,width)\n",
        "                            padding=\"valid\",              # \"same\" per renderlo della stessa dimensione dell'output\n",
        "                            dilation_rate=(1, 1),         # serve ad allargare il campo visivo del kernel\n",
        "                            groups=1,                     # channels e filtri devono essere divisibili per il numero dei gruppi, gruppi non possono essere piu grandi dei channels\n",
        "                            activation='relu',\n",
        "                            kernel_regularizer = keras.regularizers.l2(l2=l2),\n",
        "                            bias_regularizer = keras.regularizers.l2(l2=l2),\n",
        "                          )(inputs)\n",
        "  pool = keras.layers.MaxPooling2D(pool_size = (2, 2))(conv)\n",
        "  flatten = keras.layers.Flatten()(pool)\n",
        "  dense = keras.layers.Dense(units = 100,\n",
        "                               activation = 'softmax',\n",
        "                               kernel_regularizer = keras.regularizers.l2(l2=l2),\n",
        "                               bias_regularizer = keras.regularizers.l2(l2=l2)\n",
        "                               )(flatten)\n",
        "  output1 = keras.layers.Dense(units = 5,\n",
        "                               activation = 'softmax',\n",
        "                               name = 'FirstComponentClass',\n",
        "                               kernel_regularizer = keras.regularizers.l2(l2=l2),\n",
        "                               bias_regularizer = keras.regularizers.l2(l2=l2)\n",
        "                               )(dense)\n",
        "  output2 = keras.layers.Dense(5,\n",
        "                               activation = 'softmax',\n",
        "                               name = 'SecondComponentClass',\n",
        "                               kernel_regularizer = keras.regularizers.l2(l2=l2),\n",
        "                               bias_regularizer = keras.regularizers.l2(l2=l2)\n",
        "                               )(dense)\n",
        "  model = keras.Model(inputs = inputs, outputs = [output1, output2], name = \"Cifar10_Avg_Model\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "kOFxks8jsoHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Istanzio la rete neurale e mostro i suoi dettagli"
      ],
      "metadata": {
        "id": "YLIy0T4ey5N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_neural_network()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BL2eRAQAy986"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizzo un plot della rete"
      ],
      "metadata": {
        "id": "O0iFtgJQzpL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, \"model.png\", show_shapes = True, show_layer_names = True)"
      ],
      "metadata": {
        "id": "ZkOcyh9LzrAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilo la rete."
      ],
      "metadata": {
        "id": "oGs4RqwG21_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
        "    optimizer=keras.optimizers.AdamW(learning_rate = learning_rate),\n",
        "    metrics=['accuracy', 'accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "LItZbtEP23M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco una callback EarlyStopping.\n",
        "Essa valuta alla fine di ogni epoca la loss sul validation set\n",
        "e decide se fermare l'addestramento oppure no.\n",
        "Utile per stabilire automaticamente un buon numero di epoche di\n",
        "addestramento della rete."
      ],
      "metadata": {
        "id": "CRUj_b5Q5bfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',   # Monitora la loss sulla metrica indicata\n",
        "    min_delta=0.001,      # Variazione minima da considerare come miglioramento\n",
        "    patience=early_stopping_patience,          # Numero di epoche senza miglioramenti prima di fermare l'addestramento\n",
        "    mode='auto',          # oppure prende \"min\",\"max\", seleziona la direzione in automatico\n",
        "    restore_best_weights=True,  # Ripristina i pesi migliori quando l'addestramento si ferma\n",
        "    start_from_epoch=5    # Inizia il monitoraggio dall'epoca 5\n",
        ")"
      ],
      "metadata": {
        "id": "qCjqfvk25qux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addestro la rete."
      ],
      "metadata": {
        "id": "rwoCkNBs5Qw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "f1lO6tqQ5Rum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora definisco una funzione per la creazione di grafici della storia del training."
      ],
      "metadata": {
        "id": "SHZLGmdV8m8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "def plot_training_history(history):\n",
        "\n",
        "    # Estrai la loss di training e le due accuracy di validation, una per ogni output\n",
        "    training_loss = history.history['loss']\n",
        "    validation_loss = history.history['val_loss']\n",
        "    val_first_component_class_accuracy = history.history['val_FirstComponentClass_accuracy']\n",
        "    val_second_component_class_accuracy = history.history['val_SecondComponentClass_accuracy']\n",
        "    first_component_class_accuracy = history.history['FirstComponentClass_accuracy']\n",
        "    second_component_class_accuracy = history.history['SecondComponentClass_accuracy']\n",
        "\n",
        "    avg_val_accuracy = [(first_accuracy + second_accuracy) / 2 for (first_accuracy, second_accuracy) in zip(val_first_component_class_accuracy, val_second_component_class_accuracy)]\n",
        "    avg_train_accuracy = [(first_accuracy + second_accuracy) / 2 for (first_accuracy, second_accuracy) in zip(first_component_class_accuracy, second_component_class_accuracy)]\n",
        "\n",
        "    # Crea un grafico\n",
        "    epochs = range(1, len(avg_val_accuracy) + 1)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, training_loss, label='Training Loss')\n",
        "    plt.plot(epochs, validation_loss, label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, avg_train_accuracy, label='Average Training Accuracy')\n",
        "    plt.plot(epochs, avg_val_accuracy, label='Average Validation Accuracy')\n",
        "    plt.title('Average Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "uNubcBIH80jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco due funzioni per la valutazione finale del modello"
      ],
      "metadata": {
        "id": "9vI_Q8jA878f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model):\n",
        "  x_test, y_test = next(testgen)\n",
        "  if isinstance(model, keras.Model):\n",
        "    guesses = model.predict(x_test)\n",
        "    correct_guesses_1 = np.argmax(guesses[0], axis=1) == np.argmax(y_test[0], axis=1)\n",
        "    correct_guesses_2 = np.argmax(guesses[1], axis=1) == np.argmax(y_test[1], axis=1)\n",
        "  else:\n",
        "    guesses = model(x_test)\n",
        "    correct_guesses_1 = guesses[:,0] == np.argmax(y_test[0], axis=1)\n",
        "    correct_guesses_2 = guesses[:,1] == np.argmax(y_test[1], axis=1)\n",
        "  return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2)) / 2\n",
        "\n",
        "def multiple_eval_model(model, repeat_eval = 10):\n",
        "  eval_results = []\n",
        "  for i in range(repeat_eval):\n",
        "    eval_results.append(eval_model(model))\n",
        "  print(\"mean accuracy = \", np.mean(eval_results))\n",
        "  print(\"standard deviation = \", np.std(eval_results))"
      ],
      "metadata": {
        "id": "rkmPc5ET8-bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valuto la rete e il modello casuale e confronto le loro prestazioni.\n",
        "Si può facilmente dimostrare che la media delle accuratezze\n",
        "calcolata utilizzando la funzione \"multiple_eval_model\" è un numero\n",
        "appartenente all'intervallo [0,1]"
      ],
      "metadata": {
        "id": "VeGuq2s37qpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Valutazione modello casuale')\n",
        "multiple_eval_model(random_model)\n",
        "\n",
        "print('Valutazione rete neurale')\n",
        "multiple_eval_model(model)"
      ],
      "metadata": {
        "id": "Allr9jvA7vDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "machine-learning-lab-YGnFFPS1-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}