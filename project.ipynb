{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WebberMark02/machine-learning-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo le librerie necessarie e scelgo di utilizzare \"tensorflow\" come\n",
        "backend per \"Keras\"."
      ],
      "metadata": {
        "id": "gNcUV4pt1_KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist"
      ],
      "metadata": {
        "id": "VAXrS08i2CjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imposto le variabili globali."
      ],
      "metadata": {
        "id": "Seh4hYeV2Osd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 142\n",
        "training_set_size = 160000\n",
        "testing_set_size = 5000\n",
        "validation_set_size = 20000\n",
        "image_shape = (32, 32, 1)\n",
        "batch_size = 8192\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n",
        "early_stopping_patience = 50\n",
        "reduce_lr_patience = 5"
      ],
      "metadata": {
        "id": "C8nN3iR52JSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco il generatore di immagini sulle quali il modello\n",
        "verrà addestrato e testato.  \n",
        "Il generatore restituisce \"batchsize\" immagini; ogni immagine è\n",
        "la media di due immagini scelte casualmente rispettivamente da 'x1' e 'x2'.  \n",
        "Il generatore restituisce, inoltre, per ogni media di immagini, la coppia delle immagini delle quali è stata calcolata la media stessa."
      ],
      "metadata": {
        "id": "fTrSU0rn2Y3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def datagenerator(x1, x2, batchsize):\n",
        "    n1 = x1.shape[0]\n",
        "    n2 = x2.shape[0]\n",
        "    while True:\n",
        "        num1 = np.random.randint(0, n1, batchsize)\n",
        "        num2 = np.random.randint(0, n2, batchsize)\n",
        "\n",
        "        x_data = (x1[num1] + x2[num2]) / 2.0\n",
        "        y_data = (x1[num1], x2[num2])\n",
        "\n",
        "        yield x_data, y_data"
      ],
      "metadata": {
        "id": "Msxd-j1j2g5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco una funzione per il controllo del bilanciamento delle classi.  \n",
        "Mi servirà per verificare che la divisione stratificata abbia avuto successo."
      ],
      "metadata": {
        "id": "0DKB7LG33wRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stampa_percentuale(y, title = \"\"):\n",
        "  if title:\n",
        "    print(title)\n",
        "  # Calcolo le occorrenze di ciascuna classe nel dataset.\n",
        "  unique, counts = np.unique(y, return_counts = True)\n",
        "  # Calcolo la % di occorrenze per ciascuna classe.\n",
        "  percentuali = (counts / len(y)) * 100\n",
        "  # Stampo le occorrenze e le percentuali.\n",
        "  for classe, conteggio, percentuale in zip(unique, counts, percentuali):\n",
        "      print(f\"Classe {classe}: Occorrenze = {conteggio}, Percentuale {percentuale} %\" )\n",
        "  print(f\"Totale occorrenze : {sum(counts)}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "3z92DZs935J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco un modello banale.\n",
        "Mi servirà per valutare che la rete abbia prestazioni migliori di esso."
      ],
      "metadata": {
        "id": "mdVdsGyY38FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ide_model(x):\n",
        "   return((x,x))"
      ],
      "metadata": {
        "id": "Vyn_ESXT4F3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora ha inizio la fase di caricamento e preparazione dei dataset che verranno utilizzati\n",
        "per addestrare e esaminare le prestazioni della rete.\n",
        "\n",
        "Prima di tutto, carico i training set e i testing set di \"MNIST\" e \"Fashion MNIST\"."
      ],
      "metadata": {
        "id": "mKhtLevU4QS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
        "(fashion_mnist_x_train, fashion_mnist_y_train), (fashion_mnist_x_test, fashion_mnist_y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(np.shape(mnist_x_train))"
      ],
      "metadata": {
        "id": "naZI3jI34Qgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridimensiono le immagini tramite padding, portando la loro risoluzione da 28x28 a 32x32.  \n",
        "Inoltre, le normalizzo nell'intervallo [0, 1]."
      ],
      "metadata": {
        "id": "SgRovOk-4n4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize in and pad\n",
        "mnist_x_train = np.pad(mnist_x_train,((0,0),(2,2),(2,2)))/255.\n",
        "mnist_x_test = np.pad(mnist_x_test,((0,0),(2,2),(2,2)))/255.\n",
        "fashion_mnist_x_train = np.pad(fashion_mnist_x_train,((0,0),(2,2),(2,2)))/255.\n",
        "fashion_mnist_x_test = np.pad(fashion_mnist_x_test,((0,0),(2,2),(2,2)))/255.\n",
        "\n",
        "print(np.shape(mnist_x_train))"
      ],
      "metadata": {
        "id": "6EkD9Wb246KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggiungo una dimensione agli array numpy delle immagini (non modifico affatto\n",
        "le immagini).  \n",
        "Mi serve per rendere le immagini compatibili con le dimensioni\n",
        "del layer di input della rete neurale."
      ],
      "metadata": {
        "id": "xnYC3egjSTaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(mnist_x_train))\n",
        "print(np.shape(mnist_x_test))\n",
        "print(np.shape(fashion_mnist_x_train))\n",
        "print(np.shape(fashion_mnist_x_test))\n",
        "\n",
        "mnist_x_train = np.reshape(mnist_x_train, (mnist_x_train.shape[0], mnist_x_train.shape[1], mnist_x_train.shape[2], 1))\n",
        "mnist_x_test = np.reshape(mnist_x_test, (mnist_x_test.shape[0], mnist_x_test.shape[1], mnist_x_test.shape[2], 1))\n",
        "fashion_mnist_x_train = np.reshape(fashion_mnist_x_train, (fashion_mnist_x_train.shape[0], fashion_mnist_x_train.shape[1], fashion_mnist_x_train.shape[2], 1))\n",
        "fashion_mnist_x_test = np.reshape(fashion_mnist_x_test, (fashion_mnist_x_test.shape[0], fashion_mnist_x_test.shape[1], fashion_mnist_x_test.shape[2], 1))\n",
        "\n",
        "print(np.shape(mnist_x_train))\n",
        "print(np.shape(mnist_x_test))\n",
        "print(np.shape(fashion_mnist_x_train))\n",
        "print(np.shape(fashion_mnist_x_test))"
      ],
      "metadata": {
        "id": "IuJwFof8Sj0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizzo qualche immagine per accertarmi che l'operazione di reshaping non le abbia modificate."
      ],
      "metadata": {
        "id": "KthA4eTETbKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(mnist_x_train[0], cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(mnist_x_test[0], cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(fashion_mnist_x_train[0], cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(fashion_mnist_x_test[0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(mnist_x_train[0].shape)"
      ],
      "metadata": {
        "id": "ji4W6Yw-Tg-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Controllo il bilanciamento delle classi nei training set prima della divisione stratificata."
      ],
      "metadata": {
        "id": "dn2OwqKL7rbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stampa_percentuale(mnist_y_train, 'MNIST training set completo')\n",
        "stampa_percentuale(fashion_mnist_y_train, 'Fashion MNIST training set completo')"
      ],
      "metadata": {
        "id": "a7Xsfvub7uS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divido ogni training set in due insiemi: il training set e il validation set.\n",
        "Le immagini dei validation set verranno usate per l'ottimizzazione degli iper-parametri della rete.\n",
        "Ogni validation set conterrà il 20% delle immagini del training set di partenza.\n",
        "Uso la stratificazione per mantenere le classi nelle stesse proporzioni."
      ],
      "metadata": {
        "id": "b29NjrbE-V-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_x_train, mnist_x_val, mnist_y_train, mnist_y_val = sklearn.model_selection.train_test_split(mnist_x_train, mnist_y_train, test_size=0.2, stratify=mnist_y_train, random_state=seed)\n",
        "fashion_mnist_x_train, fashion_mnist_x_val, fashion_mnist_y_train, fashion_mnist_y_val = sklearn.model_selection.train_test_split(fashion_mnist_x_train, fashion_mnist_y_train, test_size=0.2, stratify=fashion_mnist_y_train, random_state=seed)"
      ],
      "metadata": {
        "id": "xENN8DNY-uZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Controllo il bilanciamento delle classi nei training set e nei validation set ottenuti dalla divisione stratificata."
      ],
      "metadata": {
        "id": "s8vTNUf2_VSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stampa_percentuale(mnist_y_train, 'MNIST training set risultante')\n",
        "stampa_percentuale(mnist_y_val, 'MNIST validation set risultante')\n",
        "\n",
        "stampa_percentuale(fashion_mnist_y_train, 'Fashion MNIST training set risultante')\n",
        "stampa_percentuale(fashion_mnist_y_val, 'Fashion MNIST validation set risultante')"
      ],
      "metadata": {
        "id": "Y88auHto_ccW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo tre istanze del generatore per generare il training set, il validation set e il testing set finali."
      ],
      "metadata": {
        "id": "k4nmLpj8AjVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traingen = datagenerator(mnist_x_train, fashion_mnist_x_train, training_set_size)\n",
        "valgen = datagenerator(mnist_x_val, fashion_mnist_x_val, validation_set_size)\n",
        "testgen = datagenerator(mnist_x_test, fashion_mnist_x_test, testing_set_size)"
      ],
      "metadata": {
        "id": "Isn3rYuF_reG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo il training set e il validation set."
      ],
      "metadata": {
        "id": "LDBwhTE0BUC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = next(traingen)\n",
        "x_val, y_val = next(valgen)"
      ],
      "metadata": {
        "id": "TiPGk0YQBN9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifico che le dimensioni dei due dataset siano corrette."
      ],
      "metadata": {
        "id": "4onlfynIBmUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "print(len(y_train))\n",
        "print(len(y_val))\n",
        "\n",
        "print(y_train[0].shape)\n",
        "print(y_train[1].shape)\n",
        "print(y_val[0].shape)\n",
        "print(y_val[1].shape)"
      ],
      "metadata": {
        "id": "7XXFelsHBZAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Controllo che i valori dei pixel delle immagini appartengano all'intervallo [0,1]."
      ],
      "metadata": {
        "id": "aXH31VvmB4Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(x_train[0]), np.max(x_train[0]))\n",
        "print(np.min(x_val[0]), np.max(x_val[0]))"
      ],
      "metadata": {
        "id": "aJZI6GD3Bq_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fase di preparazione dei dataset è completa.\n",
        "Ora viene definita e compilata la rete neurale.  \n",
        "Essa è formata da due autoencoder che condividono lo stesso layer di input.\n",
        "Ogni autoencoder restituisce una delle due immagini la cui media è l'immagine di partenza, ricostruendola il più fedelmente possibile."
      ],
      "metadata": {
        "id": "EMfzMLnICB5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_neural_network():\n",
        "    # Input Layer\n",
        "    inputs = keras.Input(shape = image_shape, name = 'InputImage')\n",
        "\n",
        "    # Encoder 1\n",
        "    enc1_conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name = 'Enc1_Conv1', kernel_initializer='random_normal', bias_initializer='zeros')(inputs)\n",
        "    enc1_pool = keras.layers.MaxPooling2D((2, 2), padding='same', name = 'Enc1_Pool')(enc1_conv1)\n",
        "    enc1_conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Enc1_Conv2', kernel_initializer='random_normal', bias_initializer='zeros')(enc1_pool)\n",
        "    encoded1 = keras.layers.MaxPooling2D((2, 2), padding='same', name = 'Encoded1')(enc1_conv2)\n",
        "\n",
        "    # Encoder 2\n",
        "    enc2_conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name = 'Enc2_Conv1', kernel_initializer='random_normal', bias_initializer='zeros')(inputs)\n",
        "    enc2_pool = keras.layers.MaxPooling2D((2, 2), padding='same', name = 'Enc2_Pool')(enc2_conv1)\n",
        "    enc2_conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Enc2_Conv2', kernel_initializer='random_normal', bias_initializer='zeros')(enc2_pool)\n",
        "    encoded2 = keras.layers.MaxPooling2D((2, 2), padding='same', name = 'Encoded2')(enc2_conv2)\n",
        "\n",
        "    # Decoder 1\n",
        "    dec1_conv1 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Dec1_Conv1', kernel_initializer='random_normal', bias_initializer='zeros')(encoded1)\n",
        "    dec1_upsampling1 = keras.layers.UpSampling2D((2, 2), name = 'Dec1_Upsampling1')(dec1_conv1)\n",
        "    dec1_conv2 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name = 'Dec1_Conv2', kernel_initializer='random_normal', bias_initializer='zeros')(dec1_upsampling1)\n",
        "    dec1_upsampling2 = keras.layers.UpSampling2D((2, 2), name = 'Dec1_Upsampling2')(dec1_conv2)\n",
        "    decoded1 = keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same', name = 'MNIST_Image', kernel_initializer='random_normal', bias_initializer='zeros')(dec1_upsampling2)\n",
        "\n",
        "    # Decoder 2\n",
        "    dec2_conv1 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name = 'Dec2_Conv1', kernel_initializer='random_normal', bias_initializer='zeros')(encoded2)\n",
        "    dec2_upsampling1 = keras.layers.UpSampling2D((2, 2), name = 'Dec2_Upsampling1')(dec2_conv1)\n",
        "    dec2_conv2 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name = 'Dec2_Conv2', kernel_initializer='random_normal', bias_initializer='zeros')(dec2_upsampling1)\n",
        "    dec2_upsampling2 = keras.layers.UpSampling2D((2, 2), name = 'Dec2_Upsampling2')(dec2_conv2)\n",
        "    decoded2 = keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same', name = 'Fashion_MNIST_Image', kernel_initializer='random_normal', bias_initializer='zeros')(dec2_upsampling2)\n",
        "\n",
        "    model = keras.Model(inputs = inputs, outputs = [decoded1, decoded2], name = 'MNIST_Reconstruction_Model')\n",
        "    return model"
      ],
      "metadata": {
        "id": "25JonRhnB620"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Istanzio la rete e mostro i suoi dettagli."
      ],
      "metadata": {
        "id": "hHLaHd0nKYy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_neural_network()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BcbYrLF7KXtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizzo un plot della rete."
      ],
      "metadata": {
        "id": "duLY3VwqMkv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, \"model.png\", show_shapes = True, show_layer_names = True)"
      ],
      "metadata": {
        "id": "1ATMl5ntKcye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco la funzione di costo che l'addestramento minimizzerà il più possibile."
      ],
      "metadata": {
        "id": "ZhSyZ298i5cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_loss = keras.losses.MeanSquaredError(\n",
        "    reduction = \"sum_over_batch_size\",\n",
        "    name = \"mean_squared_error\"\n",
        ")"
      ],
      "metadata": {
        "id": "GZVnddnEjFAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilo la rete."
      ],
      "metadata": {
        "id": "R_PT0ZSwN9iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = [mse_loss, mse_loss],\n",
        "    optimizer = keras.optimizers.AdamW(learning_rate = learning_rate),\n",
        ")"
      ],
      "metadata": {
        "id": "XF25EscDMopF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco una callback EarlyStopping. Essa valuta alla fine di ogni epoca la funzione di costo sul validation set e decide se fermare l'addestramento oppure no. Utile per stabilire automaticamente un buon numero di epoche di addestramento della rete."
      ],
      "metadata": {
        "id": "YK3VpLnZOzQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor = 'val_loss',   # Monitora la loss sulla metrica indicata\n",
        "    min_delta = 0.001,      # Variazione minima da considerare come miglioramento\n",
        "    patience = early_stopping_patience,          # Numero di epoche senza miglioramenti prima di fermare l'addestramento\n",
        "    mode = 'auto',          # oppure prende \"min\", \"max\", seleziona la direzione in automatico\n",
        "    restore_best_weights = True,  # Ripristina i pesi migliori quando l'addestramento si ferma\n",
        "    start_from_epoch = 5    # Inizia il monitoraggio dall'epoca 5\n",
        ")"
      ],
      "metadata": {
        "id": "EKXKUyu3OtBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco una callback \"BackupAndRestore\".  \n",
        "Alla fine di ogni epoca di addestramento, essa salva la rete in un file di backup temporaneo.  \n",
        "Se il notebook dovesse bloccarsi a tempo di esecuzione, sarà possibile riavviare l'addestramento ripristinando l'ultimo stato salvato nel file di backup."
      ],
      "metadata": {
        "id": "Wq84_EZnk8w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backup_and_restore = keras.callbacks.BackupAndRestore(backup_dir = \"/backup\")"
      ],
      "metadata": {
        "id": "d1kLCloDlQk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco una callback per il controllo del learning rate."
      ],
      "metadata": {
        "id": "fhs6nPEqlYRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor = 'val_loss',\n",
        "    min_delta = 0.001,\n",
        "    factor = 0.2,\n",
        "    patience = reduce_lr_patience,\n",
        "    min_lr = 0.001\n",
        ")"
      ],
      "metadata": {
        "id": "JfaFCAsmlbAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addestro la rete."
      ],
      "metadata": {
        "id": "RyIa-tbIPGlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (x_val, y_val), callbacks = [early_stopping, backup_and_restore, reduce_lr])"
      ],
      "metadata": {
        "id": "ab9vDfmTPJjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora definisco una funzione per la creazione di grafici della storia del training e visualizzo due grafici che la mostrano."
      ],
      "metadata": {
        "id": "xYD1-Rj5A903"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "def plot_training_history(history):\n",
        "\n",
        "    # Estrai la loss di training e le due accuracy di validation, una per ogni output\n",
        "    training_loss = history.history['loss']\n",
        "    validation_loss = history.history['val_loss']\n",
        "\n",
        "    # Crea un grafico\n",
        "    epochs = range(1, len(training_loss) + 1)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.plot(epochs, training_loss, label='Training Loss')\n",
        "    plt.plot(epochs, validation_loss, label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "boJA_MAKA-hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco due funzioni per la valutazione finale del modello."
      ],
      "metadata": {
        "id": "r6x9HCn8BjIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model):\n",
        "  x, (y1, y2) = next(testgen)\n",
        "  if isinstance(model, keras.Model):\n",
        "    pred1, pred2 = model.predict(x)\n",
        "  else:\n",
        "    pred1, pred2 = model(x)\n",
        "\n",
        "  return (np.mean((pred1-y1)**2) + np.mean((pred2-y2)**2) / 2)\n",
        "\n",
        "def multiple_eval_model(model, repeat_eval = 10):\n",
        "  eval_results = []\n",
        "  for i in range(repeat_eval):\n",
        "    eval_results.append(eval_model(model))\n",
        "  print(\"mse mean = \", np.mean(eval_results))\n",
        "  print(\"mse standard deviation = \", np.std(eval_results))"
      ],
      "metadata": {
        "id": "x_TV0-rpBljX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valuto la rete e il modello casuale e confronto le loro prestazioni.  \n",
        "Più questi valori sono vicini a zero, più la rete è accurata."
      ],
      "metadata": {
        "id": "KV2WbHMVCcoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Valutazione modello banale')\n",
        "multiple_eval_model(ide_model)\n",
        "\n",
        "print('Valutazione rete neurale')\n",
        "multiple_eval_model(model)"
      ],
      "metadata": {
        "id": "pvHxVF3qCf1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostriamo alcuni esempi"
      ],
      "metadata": {
        "id": "8d4aMGW0Pjm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onegen = datagenerator(mnist_x_test, fashion_mnist_x_test, 1)\n",
        "\n",
        "def show_images(x, y1, y2):\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
        "    ax[0].imshow(x,cmap='gray')\n",
        "    ax[0].title.set_text('Input')\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(y1,cmap='gray')\n",
        "    ax[1].title.set_text('mnist')\n",
        "    ax[1].axis('off')\n",
        "    ax[2].imshow(y2,cmap='gray')\n",
        "    ax[2].title.set_text('fashion_mnist')\n",
        "    ax[2].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print('Primo campione di esempio')\n",
        "x, (y1, y2) = next(onegen)\n",
        "show_images(x[0], y1[0], y2[0])\n",
        "\n",
        "print('Previsione del modello banale')\n",
        "y1_pred, y2_pred = ide_model(x)\n",
        "show_images(x[0], y1_pred[0], y2_pred[0])\n",
        "\n",
        "print('Previsione della rete neurale')\n",
        "y1_pred, y2_pred = model.predict(x)\n",
        "show_images(x[0], y1_pred[0], y2_pred[0])\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print('Secondo campione di esempio')\n",
        "x, (y1, y2) = next(onegen)\n",
        "show_images(x[0], y1[0], y2[0])\n",
        "\n",
        "print('Previsione del modello banale')\n",
        "y1_pred, y2_pred = ide_model(x)\n",
        "show_images(x[0], y1_pred[0], y2_pred[0])\n",
        "\n",
        "print('Previsione della rete neurale')\n",
        "y1_pred, y2_pred = model.predict(x)\n",
        "show_images(x[0], y1_pred[0], y2_pred[0])\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print('Terzo campione di esempio')\n",
        "x, (y1, y2) = next(onegen)\n",
        "show_images(x[0], y1[0], y2[0])\n",
        "\n",
        "print('Previsione del modello banale')\n",
        "y1_pred, y2_pred = ide_model(x)\n",
        "show_images(x[0], y1_pred[0], y2_pred[0])\n",
        "\n",
        "print('Previsione della rete neurale')\n",
        "y1_pred, y2_pred = model.predict(x)\n",
        "show_images(x[0], y1_pred[0], y2_pred[0])"
      ],
      "metadata": {
        "id": "VYDq5CNzOFb7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}